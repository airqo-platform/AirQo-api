# Great Expectations

This directory contains the configuration and expectation suites for the Great Expectations framework, which is used to validate data quality in the AirQo-api project.

## Directory Structure

- **expectations/**: Contains the expectation suites that define the data validation rules.
  - **suite/**: Exampl suite directory containing JSON files with expectations.
- **checkpoints/**: Directory for storing checkpoint configurations.
- **plugins/**: Directory for any custom plugins.
- **uncommitted/**: Directory for storing uncommitted files, such as credentials and config variables.
  - `config_variables.yml`: Example file for storing configuration variables.
- **validations/**: Directory for storing validation results.
- `great_expectations.yml`: Main configuration file for Great Expectations.

## Getting Started

To get started with Great Expectations in this project, follow these steps:

1. **Install Dependencies**:
   Ensure you have the required dependencies installed. You can install them using the `dev-requirements.txt` file in the gx directory:


   ```bash
   pip install -r dev-requirements.txt
   ```
2. **Initialize Great Expectations**:
   Initialize Great Expectations in the project directory by running the following command:
    ```bash
    great_expectations init
    ```

3. **Configure Data Sources**:
   Configure your data sources in the `great_expectations.yml` file. This file contains information about the data sources you will use for validations.

4. **Create Expectation Suites**:
   You can create new expectation suites to define the validation rules for your data:

   ```bash
   great_expectations suite new <your_suite_name>
   ```

   This will guide you through creating a new expectation suite.

5. **Run Validations**:
   You can run validations manually or integrate them into Airflow DAGs using the `GreatExpectationsOperator`.

   Example command to run validations manually:

   ```bash
   great_expectations checkpoint run <checkpoint_name>
   ```

6. **View Validation Results**:
   Validation results are stored in the `validations/` directory. You can generate and view Data Docs for a detailed report of the validation results:

   ```bash
   great_expectations docs build
   ```

7. **Add the the gx configuration**
   Add the config_variables.yml to `gx/uncommitted/` directory. This file should contain the configuration variables, environment-specific configurations, secrets, and credentials
   ```yaml
   # config_variables.yml

    # BigQuery connection string for accessing datasets
    bigquery_connection_string: "bigquery://<YOUR_PROJECT_ID>/<YOUR_DATASET_NAME>"

    # GCS bucket name where your data is stored
    gcs_bucket: "<YOUR_GCS_BUCKET_NAME>"

    # Prefix within the GCS bucket where your data files are located
    gcs_prefix: "<YOUR_DATA_PREFIX>/"

    # Credentials file path for GCP
    gcp_credentials_path: "/path/gcp/credentials.json"

    # Additional configurations for other environments or services
    # For example, if using GCP for Data Docs generated by gx
    data_docs_gcs_bucket: "<YOUR_DATA_DOCS_BUCKET>"
    data_docs_gcs_prefix: "data_docs/"

   ```

## Example

Here is an example of how to use Great Expectations in an Airflow DAG:

```python
from airflow import DAG
from airflow.operators.dummy_operator import DummyOperator
from airflow.providers.great_expectations.operators.great_expectations import GreatExpectationsOperator
from datetime import datetime

default_args = {
    'owner': 'airqo',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
}

with DAG(
    'example_great_expectations_dag',
    default_args=default_args,
    description='An example DAG with Great Expectations validations',
    schedule_interval='@daily',
    start_date=datetime(2024, 4, 6),
    catchup=False,
) as dag:
    
    start = DummyOperator(
        task_id='start',
    )

    validate_data = GreatExpectationsOperator(
        task_id='validate_data',
        expectation_suite_name='my_suite',
        batch_kwargs={
            'path': 'data/my_data_file.csv',
            'datasource': 'my_datasource',
        },
        data_context_root_dir='great_expectations',
    )

    end = DummyOperator(
        task_id='end',
    )

    start >> validate_data >> end
```

## Contributing

When contributing to this directory, please ensure that:
- Expectation suites are added to the `expectations/` directory.
- Validation results are stored in the `validations/` directory.
- Configuration changes are reflected in the `great_expectations.yml` file.

For any questions or help, feel free to reach out to the project maintainers.

Thank you for contributing to the AirQo-api!
